# Egyptian Hieroglyph Reference & Validation Project

*(Design record, execution summary, and rationale)*

## Overview

This project builds **canonical, machine-readable reference data** for Egyptian hieroglyphic signs by extracting, normalizing, and correlating information from two independent, authoritative sources:

1. **Unicode Egyptian Hieroglyph data** (from `NamesList.txt`)
2. **JSesh sign inventory** (from the JSesh catalog)

The result is **two clean JSON datasets**, generated by **two small Rust programs**, which together form the foundation for lookup, search, validation, and downstream visualization tools.

The original motivation was parsing and data normalization.
A key *side-effect* is that this work fills a long-standing tooling gap in Egyptology and digital humanities.

---

## Core Principles

* **Truth over appearance**: identity and provenance matter more than rendering
* **No silent assumptions**: gaps in Unicode or JSesh are made explicit
* **Reproducibility**: data is regenerated from upstream sources, not hand-edited
* **Locked reference snapshots**: the tool embeds data tied to specific versions
* **Downstream flexibility**: visualization and PDFs are consumers, not responsibilities

---

## The Two Rust Programs We Wrote

### Program 1: Unicode NameList Extractor

**Purpose**
Extract all Egyptian hieroglyph entries from Unicode‚Äôs `NamesList.txt` into structured JSON.

**Input**

* `NamesList.txt` from the Unicode Character Database
  (a living document updated with each Unicode release)

**What it does**

* Scans the file line-by-line
* Identifies lines beginning with `EGYPTIAN HIEROGLYPH`
* Extracts and normalizes:

  * Unicode codepoint
  * character (when renderable)
  * Unicode name
  * Gardiner identifier (e.g. `A001`)
  * Gardiner family (`A`, `B`, ‚Ä¶)

**Output JSON**
`hieroglyphs_unicode.json`

**Structure (example)**

```json
{
  "unicode_point": "U+13000",
  "codepoint_hex": "13000",
  "codepoint_dec": 77824,
  "char": "ìÄÄ",
  "unicode_name": "EGYPTIAN HIEROGLYPH A001",
  "unicode_id": "A001",
  "family": "A"
}
```

**Result**

* ~5,100 records
* Generated in < 0.1 seconds
* Deterministic and fully reproducible

This file represents **Unicode‚Äôs view of Egyptian hieroglyphs**, without interpretation.

---

### Program 2: JSesh Catalog Inventory Extractor

**Purpose**
Extract a complete inventory of JSesh sign codes and their Gardiner groupings into structured JSON.

**Input**

* Text extracted from the JSesh catalog PDF (versioned; e.g. 7.5.5)

> The PDF itself is *not* structured data.
> We intentionally treat it as text and extract only what is stable and explicit.

**What it does**

* Detects Gardiner family headers (e.g. ‚ÄúA family ‚Äì Man and his occupations‚Äù)
* Tracks the active family and description
* Extracts JSesh sign codes (`A45C`, `US1A6BEXTU`, etc.)
* Ignores layout, pagination, and rendering concerns

**Output JSON**
`hieroglyphs_jsesh_inventory.json`

**Structure (example)**

```json
{
  "family": "A",
  "family_name": "Man and his occupations",
  "jsesh_code": "A45C"
}
```

**Result**

* Complete JSesh sign inventory for the given version
* Clean separation of:

  * Gardiner family
  * family semantics
  * JSesh identifiers

This file represents **JSesh‚Äôs practical sign universe**, independent of Unicode.

---

## Why Two JSON Files (and Not One)

The separation is deliberate:

* `hieroglyphs_unicode.json` answers:

  * *What does Unicode support?*
  * *Which Gardiner signs exist in Unicode?*

* `hieroglyphs_jsesh_inventory.json` answers:

  * *What do scholars actually use in JSesh?*
  * *Which signs exist regardless of Unicode support?*

Keeping them distinct:

* preserves source authority
* avoids false equivalence
* makes gaps visible instead of hidden

Later tools can **join** these datasets ‚Äî but they should never erase their origin.

---

## Living Sources and Regeneration

Both upstream sources are **constantly evolving**:

* Unicode releases new versions regularly
* JSesh updates its catalog and sign repertoire
* Scholarly consensus shifts slowly but steadily

This project is designed so that:

* **No hand-edited reference tables exist**
* Updating means:

  1. Download new upstream sources
  2. Re-run the Rust extractors
  3. Regenerate JSON
  4. Embed the new snapshot into the tool

This makes the tool:

* future-proof
* auditable
* easy to maintain by others

Disagreements or changes belong **upstream**, not inside ad-hoc patches.

---

## Why This Is Surprisingly Useful to the Community

This was *not* the original goal ‚Äî but it emerged naturally.

### Long-standing problems in the field

* No machine-readable Gardiner sign inventory
* Unicode hieroglyphs are incomplete and opaque
* JSesh is ubiquitous but not queryable
* No validation tooling exists
* Corpus-scale analysis is extremely difficult

### What this work enables

With these two JSON datasets, the community can now:

* **Look up** any Gardiner or JSesh code programmatically
* **Validate** hieroglyphic corpora for unknown or unsupported signs
* **Audit Unicode coverage** honestly
* **Teach** using Gardiner-grouped, semantically organized references
* **Build visual grids** or PDFs without scraping PDFs again
* Treat hieroglyphic text more like **source code** than artwork

The key value is not speed (though Rust helps), but **trust and reproducibility**.

---

## Intended Direction (High-Level)

These datasets form the foundation for:

* CLI lookup tools
* Search by family, code, or Unicode support
* Corpus validators (‚Äúlinting‚Äù for hieroglyphic text)
* Data dumps for visualization (HTML/PDF/LaTeX done elsewhere)
* Long-term, versioned scholarly reference artifacts

The tool itself remains:

* conservative
* explicit
* non-interpretive

---

## Current State (Checkpoint)

* Two Rust programs written
* Two canonical JSON files generated
* Data verified with `jq`
* Performance confirmed
* Ready for:

  * GitHub check-in
  * documentation
  * future regeneration cycles

This is a **clean, well-understood foundation**.
